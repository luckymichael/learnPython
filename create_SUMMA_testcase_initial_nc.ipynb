{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import StringIO\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.chdir('D:\\Cloud\\Dropbox\\postdoc\\summa\\summaData\\columbia10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_line(s):\n",
    "    s = s.strip()\n",
    "    if s.startswith(\"'\"):\n",
    "        istart = 1\n",
    "        iend = s.find(\"'\", 1)\n",
    "    else:\n",
    "        istart = 0\n",
    "        iend = s.find(' ') + 1\n",
    "    return s[istart:iend]\n",
    "\n",
    "def read_file_manager(f_man):\n",
    "    with open(f_man, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [strip_line(l) for l in lines if l[0] != '!']\n",
    "        i = 0\n",
    "        keys = ['fman_ver', 'setting_path', 'input_path', 'output_path', 'decision', \n",
    "                'meta_time', 'meta_attr', 'meta_type', 'meta_force', 'meta_localpar',\n",
    "                'ouput_file', 'meta_index', 'meta_basinpar', 'meta_basinvar',\n",
    "                'local_attr', 'local_par', 'basin_par', 'forcing_list', 'initial_cond',\n",
    "                'para_trial', 'output_prefix']\n",
    "        file_man = OrderedDict(zip(keys, lines))\n",
    "        \n",
    "        return file_man\n",
    "\n",
    "    \n",
    "fman = 'settings_org/syntheticTestCases/wigmosta1999/summa_fileManager-exp1.txt'\n",
    "#%time file_man = read_file_manager(fman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.version.release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_file_manager(file_man, file_name):    \n",
    "    # check the maximum with for the first column\n",
    "    lens = [len(v) for v in file_man.values()]\n",
    "    width_max = max(lens) + 20\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for k in file_man:\n",
    "            line = \"'\" + file_man[k] + \"'\"\n",
    "            line = line.ljust(width_max)\n",
    "            line = line + '! ' + k + '\\n'\n",
    "            f.write(line)\n",
    "        f.close()\n",
    "#%time write_file_manager(file_man, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'settings_org/syntheticTestCases/wigmosta1999/summa_fileManager-exp1.txt1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = [len(v) for v in file_man.values()]\n",
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.56 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# find all inital state files\n",
    "def search_ini_files():\n",
    "    os.chdir('/home/mgou/Dropbox/postdoc/summa/summaTestCases')\n",
    "    ini_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk('settings_org'):\n",
    "        for f in filenames:\n",
    "            if 'summa_zInitialCond' in f:\n",
    "                ini_files.append(os.path.join(dirpath,f))\n",
    "                os.listdir(dirpath)\n",
    "%timeit search_ini_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.54 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# find all inital state files\n",
    "def search_ini_files():\n",
    "    os.chdir('/home/mgou/Dropbox/postdoc/summa/summaTestCases')\n",
    "    ini_files = []\n",
    "    for dirpath, dirnames, filenames in os.walk('settings_org'):\n",
    "        for f in filenames:\n",
    "            ini_files.append(os.path.join(dirpath,f)) if 'summa_zInitialCond' in str(f) else 'pass'\n",
    "            \n",
    "%timeit search_ini_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ini_file = 'settings_org/' + file_man['initial_cond']\n",
    "def read_ini_file(ini_file):\n",
    "    scalar_var_line = ''\n",
    "    layer_var_line = ''\n",
    "    scalar_var_block = False\n",
    "    layer_var_block = False\n",
    "    with open(ini_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            if l.startswith('!'):\n",
    "                continue\n",
    "            if 'start_scalar_icond' in l:\n",
    "                scalar_var_block = True\n",
    "                continue\n",
    "            if 'end_scalar_icond' in l:\n",
    "                scalar_var_block = False\n",
    "                continue\n",
    "            if 'start_layer_icond' in l:\n",
    "                layer_var_block = True\n",
    "                continue\n",
    "            if 'end_layer_icond' in l:\n",
    "                layer_var_block = False\n",
    "                break\n",
    "            if scalar_var_block:\n",
    "                scalar_var_line += l\n",
    "            if layer_var_block:\n",
    "                layer_var_line += l\n",
    "                \n",
    "    scalar_var = pd.read_table(StringIO(scalar_var_line), \n",
    "                               sep=' ', \n",
    "                               skipinitialspace=True, \n",
    "                               header=None,\n",
    "                               index_col=0,\n",
    "                               squeeze=True)\n",
    "    layer_var = pd.read_table(StringIO(layer_var_line), sep=' ', skipinitialspace=True)\n",
    "    return (scalar_var, layer_var) \n",
    "\n",
    "#%time scalar_var, layer_var = read_ini_file(ini_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'syntheticTestCases/wigmosta1999/summa_zParamTrial-exp1.txt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_hru_num(file):\n",
    "    '''\n",
    "    query the total number of hru in the model based on paramTrial\n",
    "    '''\n",
    "    with open(file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [l for l in lines if l[0] != '!']\n",
    "            return (len(lines) - 1)\n",
    "            \n",
    "#%time check_hru_num('settings_org/' + file_man['para_trial'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_initi_nc(nhru, scalar_var, layer_var):\n",
    "    nspec = 2\n",
    "    nmidSoil = layer_var.layerType.value_counts()['soil']\n",
    "    nifcSoil = nmidSoil + 1\n",
    "    nmidToto = layer_var.shape[0]\n",
    "    nifcToto = nmidToto + 1\n",
    "    nscalarv = 1\n",
    "\n",
    "    nSnow = np.repeat(nmidToto-nmidSoil, nhru).reshape([nscalarv, nhru]).astype(np.int32)\n",
    "    nSoil = np.repeat(nmidSoil, nhru).reshape([nscalarv, nhru]).astype(np.int32)\n",
    "    dt_init = np.repeat(scalar_var['dt_init'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarCanopyIce = np.repeat(scalar_var['scalarCanopyIce'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarCanopyLiq = np.repeat(scalar_var['scalarCanopyLiq'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarCanairTemp = np.repeat(scalar_var['scalarCanairTemp'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarCanopyTemp = np.repeat(scalar_var['scalarCanopyTemp'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarSnowAlbedo = np.repeat(scalar_var['scalarSnowAlbedo'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarSWE = np.repeat(scalar_var['scalarSWE'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarSnowDepth = np.repeat(scalar_var['scalarSnowDepth'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarSfcMeltPond = np.repeat(scalar_var['scalarSfcMeltPond'], nhru).reshape([nscalarv, nhru])\n",
    "    scalarAquiferStorage = np.repeat(scalar_var['scalarAquiferStorage'], nhru).reshape([nscalarv, nhru])\n",
    "\n",
    "    iLayerHeight_tmp = np.append(layer_var['iLayerHeight'], \n",
    "                                 layer_var.loc[nmidToto - 1,'iLayerHeight'] + layer_var.loc[nmidToto - 1,'mLayerDepth'])\n",
    "    iLayerHeight = np.repeat(iLayerHeight_tmp, nhru).reshape([nifcToto, nhru])\n",
    "    mLayerDepth  = np.repeat(layer_var['mLayerDepth'], nhru).reshape([nmidToto, nhru])\n",
    "    mLayerTemp  = np.repeat(layer_var['mLayerTemp'], nhru).reshape([nmidToto, nhru])\n",
    "    mLayerVolFracIce  = np.repeat(layer_var['mLayerVolFracIce'], nhru).reshape([nmidToto, nhru])\n",
    "    mLayerVolFracLiq  = np.repeat(layer_var['mLayerVolFracLiq'], nhru).reshape([nmidToto, nhru])\n",
    "    mLayerMatricHead  = np.repeat(layer_var['mLayerMatricHead'], nhru).reshape([nmidSoil, nhru])\n",
    "\n",
    "\n",
    "    ini_nc = xr.Dataset({'nSnow':(['scalarv', 'hru'], nSnow),\n",
    "                         'nSoil':(['scalarv', 'hru'], nSoil),\n",
    "                         'dt_init':(['scalarv', 'hru'], dt_init),\n",
    "                         'scalarCanopyIce':(['scalarv', 'hru'], scalarCanopyIce),\n",
    "                         'scalarCanopyLiq':(['scalarv', 'hru'], scalarCanopyLiq),\n",
    "                         'scalarCanairTemp':(['scalarv', 'hru'], scalarCanairTemp),\n",
    "                         'scalarCanopyTemp':(['scalarv', 'hru'], scalarCanopyTemp),\n",
    "                         'scalarSnowAlbedo':(['scalarv', 'hru'], scalarSnowAlbedo),\n",
    "                         'scalarSWE':(['scalarv', 'hru'], scalarSWE),\n",
    "                         'scalarSnowDepth':(['scalarv', 'hru'], scalarSnowDepth),\n",
    "                         'scalarSfcMeltPond':(['scalarv', 'hru'], scalarSfcMeltPond),\n",
    "                         'scalarAquiferStorage':(['scalarv', 'hru'], scalarAquiferStorage),\n",
    "                         'iLayerHeight':(['ifcToto','hru'], iLayerHeight),\n",
    "                         'mLayerDepth':(['midToto', 'hru'], mLayerDepth),\n",
    "                         'mLayerTemp':(['midToto', 'hru'], mLayerTemp),\n",
    "                         'mLayerVolFracIce':(['midToto', 'hru'], mLayerVolFracIce),\n",
    "                         'mLayerVolFracLiq':(['midToto', 'hru'], mLayerVolFracLiq),\n",
    "                         'mLayerMatricHead':(['midSoil', 'hru'], mLayerMatricHead)})\n",
    "\n",
    "    return ini_nc\n",
    "\n",
    "#nhru = check_hru_num('settings_org/' + file_man['para_trial'])      \n",
    "#scalar_var, layer_var = read_ini_file('settings_org/' + file_man['initial_cond'])\n",
    "#%time nc = create_initi_nc(nhru, scalar_var, layer_var)\n",
    "#nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### convert initial condition file to netcdf\n",
    "def convert_ini_nc(root, file_man):\n",
    "    nhru = check_hru_num(os.path.join(root, file_man['para_trial']))   \n",
    "    scalar_var, layer_var = read_ini_file(os.path.join(root, file_man['initial_cond']))\n",
    "    ini_nc = create_initi_nc(nhru, scalar_var, layer_var)\n",
    "    # strip the initial condition file\n",
    "    ini_nc_name = os.path.splitext(file_man['initial_cond'])[0] + '.nc'\n",
    "    ini_nc.to_netcdf(os.path.join(root, ini_nc_name))\n",
    "    return ini_nc_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert forcing data to netcdf (done)\n",
    "'summa_fileManager' in 'summa_fileManager_millerSand.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting settings_org\\syntheticTestCases\\celia1990/summa_fileManager_celia1990.txt\n",
      "converting settings_org\\syntheticTestCases\\miller1998/summa_fileManager_millerClay.txt\n",
      "converting settings_org\\syntheticTestCases\\miller1998/summa_fileManager_millerLoam.txt\n",
      "converting settings_org\\syntheticTestCases\\miller1998/summa_fileManager_millerSand.txt\n",
      "converting settings_org\\syntheticTestCases\\mizoguchi1990/summa_fileManager_mizoguchi.txt\n",
      "converting settings_org\\syntheticTestCases\\wigmosta1999/summa_fileManager-exp1.txt\n",
      "converting settings_org\\syntheticTestCases\\wigmosta1999/summa_fileManager-exp2.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure01/summa_fileManager_riparianAspenBeersLaw.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure01/summa_fileManager_riparianAspenCLM2stream.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure01/summa_fileManager_riparianAspenNLscatter.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure01/summa_fileManager_riparianAspenUEB2stream.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure01/summa_fileManager_riparianAspenVegParamPerturb.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure02/summa_fileManager_riparianAspenWindParamPerturb.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure03/summa_fileManager_riparianAspenExpWindProfile.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure05/summa_fileManager_9697_hedpom.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure05/summa_fileManager_9697_storck.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure05/summa_fileManager_9798_hedpom.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure05/summa_fileManager_9798_storck.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure06/summa_fileManager_reynoldsConstantDecayRate.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure06/summa_fileManager_reynoldsVariableDecayRate.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure06/summa_fileManager_senatorConstantDecayRate.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure06/summa_fileManager_senatorVariableDecayRate.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure07/summa_fileManager_riparianAspenBallBerry.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure07/summa_fileManager_riparianAspenJarvis.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure07/summa_fileManager_riparianAspenSimpleResistance.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure08/summa_fileManager_riparianAspenPerturbRoots.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure09/summa_fileManager_1dRichards.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure09/summa_fileManager_distributedTopmodel.txt\n",
      "converting settings_org\\wrrPaperTestCases\\figure09/summa_fileManager_lumpedTopmodel.txt\n"
     ]
    }
   ],
   "source": [
    "### loop all the fileManager files\n",
    "root = 'settings_org'\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    for filename in filenames:\n",
    "        if 'summa_fileManager' in filename:\n",
    "            print('converting ' + dirpath + '/' + filename)\n",
    "            file_man = read_file_manager(os.path.join(dirpath, filename))\n",
    "            # changing the output control file name\n",
    "            file_man['ouput_file'] = 'meta/Model_Output.txt'\n",
    "            # convert initial condition file to netcdf\n",
    "            if not file_man['initial_cond'].endswith('.nc'):\n",
    "                file_man['initial_cond'] = convert_ini_nc(root, file_man) \n",
    "            # write back the file manager\n",
    "            write_file_manager(file_man, os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_man = read_file_manager('summa_fileManager_columbia10.txt')\n",
    "# changing the output control file name\n",
    "file_man['ouput_file'] = 'oc_long.txt'\n",
    "# convert initial condition file to netcdf\n",
    "if not file_man['initial_cond'].endswith('.nc'):\n",
    "    file_man['initial_cond'] = convert_ini_nc(os.curdir, file_man) \n",
    "# write back the file manager\n",
    "write_file_manager(file_man, 'summa_fileManager_columbia10.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2b29ef91032a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044435667462045005"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_par = pd.DataFrame( data = [[0.045,0.43,0.15,3.0,1000,0.5],[0.08,0.43,0.04,1.6,50,0.5],[0.1,0.4,0.01,1.1,10,0.5]],\n",
    "                         index = ('sand', 'loam', 'clay'),\n",
    "                         columns = ('theta_res', 'theta_sat', 'vGn_alpha', 'vGn_n', 'k_soil', 'l'))\n",
    "\n",
    "soil_par\n",
    "\n",
    "def Se(theta, soil):\n",
    "    return (theta - soil['theta_res']) / (soil['theta_sat'] - soil['theta_res'])\n",
    "\n",
    "def theta(Se, soil):\n",
    "    return soil['theta_res'] + Se * (soil['theta_sat'] - soil['theta_res'])\n",
    "\n",
    "def SeVG(h, soil):\n",
    "    m = 1 - 1 / soil['vGn_n']\n",
    "    return (1 + (soil['vGn_alpha'] * abs(h)) ** soil['vGn_n']) ** (-m)\n",
    "\n",
    "Se(0.3, soil_par.loc['sand'])\n",
    "SeVG(-100, soil_par.loc['sand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:      (depth: 200)\n",
       "Coordinates:\n",
       "  * depth        (depth) int64 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ...\n",
       "Data variables:\n",
       "    theta_res    (depth) float64 0.045 0.045 0.045 0.045 0.045 0.045 0.045 ...\n",
       "    vGn_n        (depth) float64 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 ...\n",
       "    vGn_alpha    (depth) float64 1.5e-09 1.5e-09 1.5e-09 1.5e-09 1.5e-09 ...\n",
       "    theta_sat    (depth) float64 0.43 0.43 0.43 0.43 0.43 0.43 0.43 0.43 ...\n",
       "    k_soil       (depth) float64 0.0001157 0.0001157 0.0001157 0.0001157 ...\n",
       "    k_macropore  (depth) float64 0.0001157 0.0001157 0.0001157 0.0001157 ...\n",
       "    theta_mp     float64 0.43"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(hruId=('hru',1001),rootingDepth=('hru',0.0))\n",
    "xr.Dataset(dict(hruId=('hru',[1001]),rootingDepth=('hru',[0.0])))\n",
    "par + ['l']\n",
    "ds.vGn_alpha.values = ds.vGn_alpha * 0.01\n",
    "ds.vGn_alpha\n",
    "xr.concat([ds, ds.isel(depth=range(50,100))], dim='depth')\n",
    "ds.isel(depth=np.concatenate([np.arange(0, 100), np.arange(50, 100),np.arange(50, 100)]))\n",
    "np.concatenate([np.arange(0, 100), np.arange(50, 100),np.arange(50, 100)])\n",
    "ds\n",
    "#ds['theta_mp'] = ds.theta_sat.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'theta_mp' (hru: 1)>\n",
       "array([ 0.5])\n",
       "Coordinates:\n",
       "  * hru      (hru) int64 0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_hru['theta_mp']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set2\n",
      "set1\n",
      "set3\n"
     ]
    }
   ],
   "source": [
    "############################################### \n",
    "############### soil parameter\n",
    "###############################################\n",
    "par = ['theta_res', 'theta_sat', 'vGn_alpha', 'vGn_n', 'k_soil']\n",
    "soil_par = pd.DataFrame( data = [[0.045, 0.43, 0.15, 3.0, 1000, 0.5],\n",
    "                                 [0.08,  0.43, 0.04, 1.6, 50,   0.5],\n",
    "                                 [0.1,   0.4,  0.01, 1.1, 10,   0.5]],\n",
    "                         index = ('sand', 'loam', 'clay'),\n",
    "                         columns = par + ['l'])\n",
    "\n",
    "layer = dict(set1=('loam', 'sand'), set2=('sand', 'loam'), set3=('clay','sand'))\n",
    "nlayers = [50, 150]\n",
    "ds_hru = xr.Dataset(dict(hruId=('hru',[1001]),rootingDepth=('hru',[0.02]),theta_mp=('hru', [0.5])))\n",
    "for k in layer.keys():\n",
    "    print(k)\n",
    "    ds = xr.concat(\n",
    "        [\n",
    "            xr.Dataset({p:(['depth'], np.repeat(soil_par.loc[l][p], n )) for p in par}) \n",
    "            for l, n in zip(layer[k], nlayers)\n",
    "        ], \n",
    "        dim='depth')\n",
    "    #ds = ds.isel(depth=np.concatenate([np.arange(0, 100), np.arange(50, 100),np.arange(50, 100)]))\n",
    "    ds.vGn_alpha.values = -ds.vGn_alpha * 100\n",
    "    ds.k_soil.values = ds.k_soil * 0.01 / 86400\n",
    "    ds['k_macropore'] = ds.k_soil\n",
    "    #ds_hru['theta_mp'].values = ds.theta_sat.values[0]\n",
    "    ds = xr.merge([xr.broadcast(ds, ds_hru)[0], ds_hru])\n",
    "    ds.drop('depth')\n",
    "    ds.to_netcdf(\n",
    "        r'D:\\Cloud\\Dropbox\\postdoc\\summa\\summaData\\summaTestCases\\settings_org\\syntheticTestCases\\vanderborght2005\\summa_zParamTrial_vanderborght2005_' \n",
    "        + k + '.nc')\n",
    "\n",
    "# print(date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 10)>\n",
       "array(['1990-01-01T00:00:00.000000000', '1990-04-11T00:00:00.000000000',\n",
       "       '1990-07-20T00:00:00.000000000', '1990-10-28T00:00:00.000000000',\n",
       "       '1991-02-05T00:00:00.000000000', '1991-05-16T00:00:00.000000000',\n",
       "       '1991-08-24T00:00:00.000000000', '1991-12-02T00:00:00.000000000',\n",
       "       '1992-03-11T00:00:00.000000000', '1992-06-19T00:00:00.000000000'], dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1990-01-01 1990-04-11 1990-07-20 ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### \n",
    "############### local attribute\n",
    "###############################################\n",
    "ds.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theta_res       0.045\n",
       "theta_sat       0.430\n",
       "vGn_alpha       0.150\n",
       "vGn_n           3.000\n",
       "k_soil       1000.000\n",
       "l               0.500\n",
       "Name: sand, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_par.loc['sand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.108449606138\n"
     ]
    }
   ],
   "source": [
    "############################################### \n",
    "############### initial condition\n",
    "###############################################\n",
    "\n",
    "\n",
    "def Se(theta, soil):\n",
    "    return (theta - soil['theta_res']) / (soil['theta_sat'] - soil['theta_res'])\n",
    "\n",
    "def theta(Se, soil):\n",
    "    return soil['theta_res'] + Se * (soil['theta_sat'] - soil['theta_res'])\n",
    "\n",
    "def SeVG(h, soil):\n",
    "    m = 1 - 1 / soil['vGn_n']\n",
    "    return (1 + (soil['vGn_alpha'] * abs(h)) ** soil['vGn_n']) ** (-m)\n",
    "\n",
    "Se(0.3, soil_par.loc['sand'])\n",
    "\n",
    "print(SeVG(-20, soil_par.loc['sand']))\n",
    "\n",
    "nspec = 2\n",
    "nmidSoil = 200\n",
    "nifcSoil = nmidSoil + 1\n",
    "nmidToto = nmidSoil\n",
    "nifcToto = nmidToto + 1\n",
    "nscalarv = 1\n",
    "nhru = 1\n",
    "    \n",
    "ini_nc = xr.Dataset({'nSnow':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'nSoil':(['scalarv', 'hru'], np.array([[200]])),\n",
    "                     'dt_init':(['scalarv', 'hru'], np.array([[60]])),\n",
    "                     'scalarCanopyIce':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'scalarCanopyLiq':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'scalarCanairTemp':(['scalarv', 'hru'], np.array([[283.16]])),\n",
    "                     'scalarCanopyTemp':(['scalarv', 'hru'], np.array([[283.16]])),\n",
    "                     'scalarSnowAlbedo':(['scalarv', 'hru'], np.array([[0.82]])),\n",
    "                     'scalarSWE':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'scalarSnowDepth':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'scalarSfcMeltPond':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'scalarAquiferStorage':(['scalarv', 'hru'], np.array([[0]])),\n",
    "                     'iLayerHeight':(['ifcToto', 'hru'], np.arange(0,2.01,0.01).reshape([nifcToto, nhru])),\n",
    "                     'mLayerDepth':(['midToto', 'hru'], np.repeat(0.01, 200).reshape([nmidToto, nhru])),\n",
    "                     'mLayerTemp':(['midToto', 'hru'], np.repeat(283.16, 200).reshape([nmidToto, nhru])),\n",
    "                     'mLayerVolFracIce':(['midToto', 'hru'], np.repeat(0, 200).reshape([nmidToto, nhru])),\n",
    "                     'mLayerVolFracLiq':(['midToto', 'hru'], np.repeat(0.3, 200).reshape([nmidToto, nhru])),\n",
    "                     'mLayerMatricHead':(['midSoil', 'hru'], np.repeat(-20, 200).reshape([nmidToto, nhru]))\n",
    "                    })\n",
    "h = xr.Dataset(dict(hruId=('hru', [1001])))\n",
    "ds = xr.merge([ini_nc, h])\n",
    "ds.to_netcdf(r'D:\\Cloud\\Dropbox\\postdoc\\summa\\summaData\\summaTestCases\\settings_org\\syntheticTestCases\\vanderborght2005\\summa_zInitialCond_vanderborght2005.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 10)>\n",
       "array(['1990-01-01T00:00:00.000000000', '1992-09-27T00:00:00.000000000',\n",
       "       '1995-06-24T00:00:00.000000000', '1998-03-20T00:00:00.000000000',\n",
       "       '2000-12-14T00:00:00.000000000', '2003-09-10T00:00:00.000000000',\n",
       "       '2006-06-06T00:00:00.000000000', '2009-03-02T00:00:00.000000000',\n",
       "       '2011-11-27T00:00:00.000000000', '2014-08-23T00:00:00.000000000'], dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1990-01-01 1992-09-27 1995-06-24 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################### \n",
    "############### forcing\n",
    "###############################################\n",
    "nday = 1000\n",
    "f = xr.Dataset(dict(pptrate =('time', np.repeat(0.5*10/3600/24,   10)),\n",
    "                    LWRadAtm=('time', np.repeat(350,              10)),\n",
    "                    SWRadAtm=('time', np.repeat(0,                10)),\n",
    "                    airpres =('time', np.repeat(101325,           10)),\n",
    "                    airtemp =('time', np.repeat(283.16,           10)),\n",
    "                    spechum =('time', np.repeat(0.0028,           10)),\n",
    "                    windspd =('time', np.repeat(0,                10)),\n",
    "                    time    =('time', pd.date_range('1/1/1990', periods=10, freq=str(nday) + 'D'))\n",
    "                   )\n",
    "               )\n",
    "h = xr.Dataset(dict(hruId=('hru', [1001]), data_step=(86400*nday)))\n",
    "ds = xr.merge([xr.broadcast(f, h)[0], h])\n",
    "ds.to_netcdf(r'D:\\Cloud\\Dropbox\\postdoc\\summa\\summaData\\summaTestCases\\testCases_data_org\\inputData\\syntheticData\\vanderborght2005\\vanderborght2005_forcing.nc')\n",
    "ds.time"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
